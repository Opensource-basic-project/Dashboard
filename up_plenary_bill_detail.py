from db import SessionLocal, PlenaryBill
import requests
from bs4 import BeautifulSoup
import time

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}

def crawl_plenary_proposal_text(link_url: str):
    try:
        response = requests.get(link_url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        summary_div = soup.find("div", id="summaryContentDiv")
        if summary_div:
            return summary_div.get_text(separator="\n").strip()
    except Exception as e:
        print(f"[μ—λ¬] {link_url} μ²λ¦¬ μ¤‘ μ¤λ¥: {e}")
    return None

def update_plenary_proposal_text():
    db = SessionLocal()
    try:
        targets = db.query(PlenaryBill).filter(
            (PlenaryBill.proposal_text == None) |
            (PlenaryBill.proposal_text == "")
        ).all()

        for bill in targets:
            if bill.link_url:
                print(f"[λ³Ένμ] π“„ {bill.bill_name} - ν¬λ΅¤λ§ μ‹λ„ μ¤‘...")
                detail = crawl_plenary_proposal_text(bill.link_url)
                if not detail:
                    print(f"[λ³Ένμ] β 1μ°¨ μ‹¤ν¨, μ¬μ‹λ„ μ¤‘...")
                    time.sleep(1)
                    detail = crawl_plenary_proposal_text(bill.link_url)
                if detail:
                    bill.proposal_text = detail
                else:
                    print(f"[λ³Ένμ] π« ν¬λ΅¤λ§ μ‹¤ν¨: {bill.link_url}")
                time.sleep(1)
        db.commit()
        print("[λ³Ένμ] β… μ μ•μ΄μ  λ° μ£Όμ”λ‚΄μ© DB κ°±μ‹  μ™„λ£")
    finally:
        db.close()

if __name__ == "__main__":
    update_plenary_proposal_text()
